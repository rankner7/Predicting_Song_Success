{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1870664 entries, 0 to 1870663\n",
      "Data columns (total 19 columns):\n",
      "Artist(s)           object\n",
      "Date                object\n",
      "Duration            int64\n",
      "Popularity          int64\n",
      "Song Title          object\n",
      "Success             int64\n",
      "acousticness        float64\n",
      "danceability        float64\n",
      "energy              float64\n",
      "id                  object\n",
      "instrumentalness    float64\n",
      "key                 int64\n",
      "liveness            float64\n",
      "loudness            float64\n",
      "mode                int64\n",
      "speechiness         float64\n",
      "tempo               float64\n",
      "time_signature      int64\n",
      "valence             float64\n",
      "dtypes: float64(9), int64(6), object(4)\n",
      "memory usage: 271.2+ MB\n",
      "None\n",
      "Good Split\n",
      "\n",
      "Train Set Size: 70.00%\n",
      "Test Set Size:  30.00%\n",
      "\n",
      "Overall Success:   0.31096%\n",
      "Training Success:  0.31456%\n",
      "Test Success:      0.30257%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from random import sample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "def scale_data(frame):\n",
    "    cols = frame.columns\n",
    "    frame = pd.DataFrame(sc.fit_transform(frame))\n",
    "    frame.columns = cols\n",
    "    \n",
    "    return frame\n",
    "\n",
    "def construct_confusion(truth, prediction):\n",
    "    #Construct Confusion matrix\n",
    "    confusion = np.array([[0,0],[0,0]])\n",
    "    for i in range(0, len(truth)):\n",
    "        if (truth[i] == 0):\n",
    "            if prediction[i] == 0:\n",
    "                confusion[0,0] += 1\n",
    "            else:\n",
    "                confusion[0,1] += 1\n",
    "        else:\n",
    "            if prediction[i] == 0:\n",
    "                confusion[1,0] += 1\n",
    "            else:\n",
    "                confusion[1,1] += 1\n",
    "                \n",
    "    return confusion/len(truth)\n",
    "\n",
    "def print_confusion(confusion):\n",
    "    print(\"\\n   Predicted Class\")\n",
    "    print(\"      0  |   1\")\n",
    "    print(\"0 | %.2f | %.2f |\"%(confusion[0,0], confusion[0,1]))\n",
    "    print(\"1 | %.2f | %.2f |\\n\"%(confusion[1,0], confusion[1,1]))\n",
    "\n",
    "def print_accuracy(trained_model, X, X_test, Y, Y_test):\n",
    "    prediction = trained_model.predict(X)\n",
    "    truth = Y.to_numpy()\n",
    "    diff = truth - prediction\n",
    "\n",
    "    confusion_train = construct_confusion(truth, prediction)\n",
    "\n",
    "    print(\"Training Accuracy: %.2f%%\"%(100 - np.sum(np.abs(diff))*100/len(truth)))\n",
    "    print_confusion(confusion_train)\n",
    "\n",
    "    prediction = trained_model.predict(X_test)\n",
    "    truth = Y_test.to_numpy()\n",
    "    diff = truth - prediction\n",
    "\n",
    "    confusion_test = construct_confusion(truth, prediction)\n",
    "\n",
    "    print(\"Test Accuracy: %.2f%%\"%(100 - np.sum(np.abs(diff))*100/len(truth)))\n",
    "    print_confusion(confusion_test)\n",
    "\n",
    "    print(\"In-Sample Percent Survivor: %.2f%%\"%((confusion_train[1,1]*100)/(confusion_train[1,1]+confusion_train[1,0])))\n",
    "    print(\"In-Sample Percent Fatality: %.2f%%\"%((confusion_train[0,0]*100)/(confusion_train[0,1]+confusion_train[0,0])))\n",
    "    print(\"Out-Sample Percent Survivor: %.2f%%\"%((confusion_test[1,1]*100)/(confusion_test[1,1]+confusion_test[1,0])))\n",
    "    print(\"Out-Sample Percent Fatality: %.2f%%\"%((confusion_test[0,0]*100)/(confusion_test[0,1]+confusion_test[0,0])))\n",
    "\n",
    "def split_train_and_test(full_dataset, percent_split):\n",
    "    if not(percent_split > 0 and percent_split < 1):\n",
    "        print(\"Invalid Split: Value must be between 0 and 1\")\n",
    "        return None\n",
    "\n",
    "    data_points = full_dataset.shape[0]\n",
    "\n",
    "    #Create Training_list\n",
    "    training_list = sample(range(data_points), int(percent_split*data_points))\n",
    "    training_list.sort()\n",
    "\n",
    "    #Create Test List\n",
    "    full = [x for x in range(0,data_points)]\n",
    "    full_set = set(full)\n",
    "    test_list = list(full_set - set(training_list))\n",
    "    test_list.sort()\n",
    "\n",
    "    training_set = full_dataset.iloc[training_list]\n",
    "    test_set = full_dataset.iloc[test_list]\n",
    "\n",
    "    training_set.reset_index(inplace=True, drop=True)\n",
    "    test_set.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    if (training_set.shape[0] + test_set.shape[0]) == data_points:\n",
    "        print(\"Good Split\")\n",
    "        return {'training_set':training_set, 'test_set': test_set}\n",
    "    else:\n",
    "        print(\"Whoops! BAD SPLIT. Not sure what happened :/\")\n",
    "        return None\n",
    "\n",
    "def print_set_info(full_set, X, X_test, Y, Y_test):\n",
    "    print(\"\\nTrain Set Size: %.2f%%\"%(X.shape[0]*100/full_set.shape[0]))\n",
    "    print(\"Test Set Size:  %.2f%%\"%(X_test.shape[0]*100/full_set.shape[0]))\n",
    "\n",
    "    success = np.sum(full_set['Success'].to_numpy())\n",
    "    total = len(full_set['Success'].to_numpy())\n",
    "    print(\"\\nOverall Success:   %.5f%%\"%(success*100/total))\n",
    "\n",
    "    success = np.sum(Y.to_numpy())\n",
    "    total = len(Y.to_numpy())\n",
    "    print(\"Training Success:  %.5f%%\"%(success*100/total))\n",
    "\n",
    "    success = np.sum(Y_test.to_numpy())\n",
    "    total = len(Y_test.to_numpy())\n",
    "    print(\"Test Success:      %.5f%%\"%(success*100/total))\n",
    "\n",
    "\n",
    "data_file = \"../data/full_dataset.csv\"\n",
    "big_frame = pd.read_csv(data_file, index_col=False)\n",
    "big_frame = big_frame.astype({'Success': int})\n",
    "print(big_frame.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Split\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99060 entries, 0 to 99059\n",
      "Data columns (total 19 columns):\n",
      "Artist(s)           99060 non-null object\n",
      "Date                99060 non-null object\n",
      "Duration            99060 non-null int64\n",
      "Popularity          99060 non-null int64\n",
      "Song Title          99060 non-null object\n",
      "Success             99060 non-null int64\n",
      "acousticness        99060 non-null float64\n",
      "danceability        99060 non-null float64\n",
      "energy              99060 non-null float64\n",
      "id                  99060 non-null object\n",
      "instrumentalness    99060 non-null float64\n",
      "key                 99060 non-null int64\n",
      "liveness            99060 non-null float64\n",
      "loudness            99060 non-null float64\n",
      "mode                99060 non-null int64\n",
      "speechiness         99060 non-null float64\n",
      "tempo               99060 non-null float64\n",
      "time_signature      99060 non-null int64\n",
      "valence             99060 non-null float64\n",
      "dtypes: float64(9), int64(6), object(4)\n",
      "memory usage: 14.4+ MB\n",
      "None\n",
      "Good Split\n",
      "\n",
      "Train Set Size: 70.00%\n",
      "Test Set Size:  30.00%\n",
      "\n",
      "Overall Success:   5.87220%\n",
      "Training Success:  5.83917%\n",
      "Test Success:      5.94926%\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'Duration',\n",
    "    'acousticness',\n",
    "    'danceability',\n",
    "    'energy', \n",
    "    'instrumentalness',\n",
    "    'key',\n",
    "    'liveness',\n",
    "    'loudness',\n",
    "    'mode',\n",
    "    'speechiness',\n",
    "    'tempo',\n",
    "    'time_signature',\n",
    "    'valence'\n",
    "]\n",
    "target = 'Success'\n",
    "successes = big_frame[big_frame['Success']==1]\n",
    "not_successes = big_frame[big_frame['Success']==0]\n",
    "\n",
    "get_less = split_train_and_test(not_successes, 0.95)\n",
    "subset = get_less['test_set']\n",
    "\n",
    "new_frame = pd.concat([successes, subset], axis=0, ignore_index=True)\n",
    "print(new_frame.info())\n",
    "\n",
    "data_sets = split_train_and_test(new_frame, 0.7)\n",
    "training_set = data_sets['training_set']\n",
    "test_set = data_sets['test_set']\n",
    "\n",
    "X = training_set[features]\n",
    "X = scale_data(X)\n",
    "Y = training_set[target]\n",
    "\n",
    "X_test = test_set[features]\n",
    "X_test = scale_data(X_test)\n",
    "Y_test = test_set[target]\n",
    "\n",
    "print_set_info(new_frame, X, X_test, Y, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 253.46995808\n",
      "Iteration 2, loss = 227.52529571\n",
      "Iteration 3, loss = 301.90721043\n",
      "Iteration 4, loss = 284.88883190\n",
      "Iteration 5, loss = 257.33537852\n",
      "Iteration 6, loss = 252.34830905\n",
      "Iteration 7, loss = 116.53713838\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "        hidden_layer_sizes = (5000,100),\n",
    "        solver='adam',\n",
    "        activation='logistic',\n",
    "        batch_size = int(0.01*X.shape[0]),\n",
    "        learning_rate='adaptive',\n",
    "        learning_rate_init=1,\n",
    "        verbose=True,\n",
    "        momentum=0.5,\n",
    "        alpha = 2,\n",
    "        max_iter = 10000,\n",
    "        random_state=1\n",
    "    )\n",
    "\n",
    "clf.fit(X,Y)\n",
    "print_accuracy(clf, X, X_test, Y, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'Duration',\n",
    "    'acousticness',\n",
    "    'danceability',\n",
    "    'energy', \n",
    "    'instrumentalness',\n",
    "    'key',\n",
    "    'liveness',\n",
    "    'loudness',\n",
    "    'mode',\n",
    "    'speechiness',\n",
    "    'tempo',\n",
    "    'time_signature',\n",
    "    'valence',\n",
    "    'Popularity'\n",
    "]\n",
    "\n",
    "success = new_frame[new_frame['Success'] == 1]\n",
    "\n",
    "not_success = new_frame[new_frame['Success']==0]\n",
    "\n",
    "colors = ['green', 'red']\n",
    "for feat in features:\n",
    "    plt.hist([success[feat], not_success[feat]], 20, density=True, histtype='bar', color=colors, label=['Success', 'Not Sucess'])\n",
    "    #plt.hist([survived_predict, died_predict], 20, stacked=True, histtype='step', color=colors, label=['survived', 'died'])\n",
    "    plt.title(feat)\n",
    "    plt.legend(prop={'size': 10})\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
