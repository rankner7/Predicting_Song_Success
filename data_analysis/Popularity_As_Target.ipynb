{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1870664 entries, 0 to 1870663\n",
      "Data columns (total 19 columns):\n",
      "Artist(s)           object\n",
      "Date                object\n",
      "Duration            int64\n",
      "Popularity          int64\n",
      "Song Title          object\n",
      "Success             int64\n",
      "acousticness        float64\n",
      "danceability        float64\n",
      "energy              float64\n",
      "id                  object\n",
      "instrumentalness    float64\n",
      "key                 int64\n",
      "liveness            float64\n",
      "loudness            float64\n",
      "mode                int64\n",
      "speechiness         float64\n",
      "tempo               float64\n",
      "time_signature      int64\n",
      "valence             float64\n",
      "dtypes: float64(9), int64(6), object(4)\n",
      "memory usage: 271.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from random import sample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "def scale_data(frame):\n",
    "    cols = frame.columns\n",
    "    frame = pd.DataFrame(sc.fit_transform(frame))\n",
    "    frame.columns = cols\n",
    "    \n",
    "    return frame\n",
    "\n",
    "def split_train_and_test(full_dataset, percent_split):\n",
    "    if not(percent_split > 0 and percent_split < 1):\n",
    "        print(\"Invalid Split: Value must be between 0 and 1\")\n",
    "        return None\n",
    "\n",
    "    data_points = full_dataset.shape[0]\n",
    "\n",
    "    #Create Training_list\n",
    "    training_list = sample(range(data_points), int(percent_split*data_points))\n",
    "    training_list.sort()\n",
    "\n",
    "    #Create Test List\n",
    "    full = [x for x in range(0,data_points)]\n",
    "    full_set = set(full)\n",
    "    test_list = list(full_set - set(training_list))\n",
    "    test_list.sort()\n",
    "\n",
    "    training_set = full_dataset.iloc[training_list]\n",
    "    test_set = full_dataset.iloc[test_list]\n",
    "\n",
    "    training_set.reset_index(inplace=True, drop=True)\n",
    "    test_set.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    if (training_set.shape[0] + test_set.shape[0]) == data_points:\n",
    "        print(\"Good Split\")\n",
    "        return {'training_set':training_set, 'test_set': test_set}\n",
    "    else:\n",
    "        print(\"Whoops! BAD SPLIT. Not sure what happened :/\")\n",
    "        return None\n",
    "\n",
    "def show_results(trained_model, X, Y):\n",
    "    try:\n",
    "        truth = Y.to_numpy()\n",
    "    except:\n",
    "        truth = Y\n",
    "    \n",
    "    prediction = trained_model.predict(X)\n",
    "    prediction = np.around(prediction)\n",
    "    \n",
    "    #Scale to within range\n",
    "    predict_series = pd.Series(prediction)\n",
    "    upper = np.amax(truth)\n",
    "    lower = np.amin(truth)\n",
    "    predict_series[predict_series < lower] = lower\n",
    "    predict_series[predict_series > upper] = upper\n",
    "    \n",
    "    prediction = predict_series.to_numpy()\n",
    "\n",
    "    print(\"Max, Min: \", np.amax(prediction), np.amin(prediction))\n",
    "    diff = truth - prediction\n",
    "    \n",
    "    rand_prediction = np.random.randint(np.amin(truth), np.amax(truth)+1, len(truth))\n",
    "    rand_diff = truth - rand_prediction\n",
    "    \n",
    "    ave_SSE = np.sqrt(np.dot(diff, diff))/len(Y)\n",
    "    print(\"\\nAverage Error (Actual): %.4f\"%(ave_SSE))\n",
    "    ave_rand_SSE = np.sqrt(np.dot(rand_diff, rand_diff))/len(Y)\n",
    "    print(\"Average Error (Random): %.4f\"%(ave_rand_SSE))\n",
    "    \n",
    "    diff_series = pd.Series(diff).value_counts()\n",
    "    diff_cnts = diff_series.to_numpy()\n",
    "    total = np.sum(diff_cnts)\n",
    "    diff_labels = diff_series.index.values\n",
    "    \n",
    "    num_classes = len(Y.value_counts().to_numpy())\n",
    "    print_class_breakdown(truth, \"Actual\", 5, True)\n",
    "    print_class_breakdown(prediction, \"Prediction\", 5, False)\n",
    "    print_class_breakdown(rand_prediction, \"Random\", 5, False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"\\nError Breakdown:\")\n",
    "    max_label = 5\n",
    "    for i in range(-len(Y.value_counts()), (len(Y.value_counts())+1)):\n",
    "        label = \" \"*max_label+str(i)\n",
    "        label = label[len(label)-max_label:len(label)]\n",
    "        print(label, end='|  ')\n",
    "        if i in diff_labels:\n",
    "            perc = diff_cnts[diff_labels.tolist().index(i)]*100/total\n",
    "        else:\n",
    "            perc = 0\n",
    "        \n",
    "        print(\"%.2f%%\"%(perc))\n",
    "    \n",
    "    #plt.hist([diff, rand_diff], 8, density=True, histtype='bar', color=['green', 'red'], label=['Actual', 'Random Guessing'])\n",
    "    plt.hist([diff, rand_diff], 8, density=True, color=['green', 'red'], label=['Actual', 'Random Guessing'])\n",
    "    plt.title(\"Difference Histogram\")\n",
    "    plt.legend(prop={'size': 10})\n",
    "    plt.show()\n",
    "    \n",
    "def print_class_breakdown(dataset, desc, num_classes, class_label):\n",
    "    try:\n",
    "        breakdown = dataset['Success'].value_counts()\n",
    "    except:\n",
    "        dataset = pd.Series(dataset)\n",
    "        breakdown = dataset.value_counts()\n",
    "    \n",
    "    classes = breakdown.index.values\n",
    "    \n",
    "    breakdown = breakdown.to_numpy()\n",
    "    total = np.sum(breakdown)\n",
    "\n",
    "    max_desc = 14\n",
    "    if (class_label):\n",
    "        print(\" \"*(max_desc+5), end=\"\")\n",
    "        for i in range(0, num_classes):\n",
    "            print(i, end=\" \"*9)\n",
    "        print(\"\")\n",
    "            \n",
    "    desc = desc + \" \"*max_desc\n",
    "    desc = desc[0:max_desc]\n",
    "    print(desc, end=\"| \")\n",
    "    for cnt in range(0,num_classes):\n",
    "        if cnt in classes:\n",
    "            perc = breakdown[classes.tolist().index(cnt)]*100/total\n",
    "        else:\n",
    "            perc = 0\n",
    "        num_string = \" \"*8+\" %.3f%%\"%(perc)\n",
    "        num_string = num_string[len(num_string)-8:len(num_string)]\n",
    "        print(num_string, end=\"  \")\n",
    "    print(\"\")\n",
    "\n",
    "def print_set_info(full_set, Y, Y_test):\n",
    "    print(\"\\nTrain Set Size: %.2f%% --> %d\"%(Y.shape[0]*100/(Y.shape[0]+Y_test.shape[0]), Y.shape[0]))\n",
    "    print(\"Test Set Size:  %.2f%% --> %d\\n\"%(Y_test.shape[0]*100/(Y.shape[0]+Y_test.shape[0]), Y_test.shape[0]))\n",
    "\n",
    "    print(\"Success Classification:\")\n",
    "    num_classes = len(full_set['Success'].value_counts().to_numpy())\n",
    "    \n",
    "    print_class_breakdown(full_set, \"Full Dataset\", num_classes, True)\n",
    "    print_class_breakdown(Y, \"Training Set\", num_classes, False)\n",
    "    print_class_breakdown(Y_test, \"Test Set\", num_classes, False)\n",
    "\n",
    "def add_year(dataset):\n",
    "    year_list = []\n",
    "    for date in dataset['Date']:\n",
    "        year = date.split('-')[0]\n",
    "        if year is not(None):\n",
    "            if int(year) > 1800:\n",
    "                year_list.append(int(year))\n",
    "            else:\n",
    "                year_list.append(int(0))\n",
    "    \n",
    "    dataset['Year'] = year_list\n",
    "    dataset = dataset[dataset['Year'] > 1800]\n",
    "    dataset.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def enumerate_popularity(range_list, dataset):\n",
    "    en_frame = pd.DataFrame(columns=list(dataset))\n",
    "    for i,rng in enumerate(range_list):\n",
    "        sub_frame = dataset[(dataset['Popularity'] >= rng[0]) & (dataset['Popularity'] < rng[1])]\n",
    "        sub_frame['Success'] = [i]*sub_frame.shape[0]\n",
    "        en_frame = pd.concat([en_frame, sub_frame], axis=0, ignore_index=True)\n",
    "        print(\"Subset [%d, %d], Class %d --> %.3f%%\"%(rng[0], rng[1], i, (sub_frame.shape[0]*100/dataset.shape[0])))\n",
    "    \n",
    "    return en_frame\n",
    "   \n",
    "data_file = \"../data/full_dataset.csv\"\n",
    "big_frame = pd.read_csv(data_file, index_col=False)\n",
    "big_frame = big_frame.astype({'Success': int})\n",
    "print(big_frame.info())\n",
    "\n",
    "big_frame = add_year(big_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ronnie/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset [0, 10], Class 0 --> 61.916%\n",
      "Subset [10, 30], Class 1 --> 25.021%\n",
      "Subset [30, 50], Class 2 --> 10.360%\n",
      "Subset [50, 100], Class 3 --> 2.703%\n",
      "0    1158182\n",
      "1     468040\n",
      "2     193781\n",
      "3      50552\n",
      "Name: Success, dtype: int64\n",
      "Good Split\n",
      "Good Split\n",
      "\n",
      "Train Set Size: 70.00% --> 392816\n",
      "Test Set Size:  30.00% --> 168350\n",
      "\n",
      "Success Classification:\n",
      "                   0         1         2         3         \n",
      "Full Dataset  |  61.916%   25.021%   10.360%    2.703%  \n",
      "Training Set  |  61.982%   24.971%   10.322%    2.724%  \n",
      "Test Set      |  61.795%   25.010%   10.460%    2.734%  \n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'Duration',\n",
    "    'acousticness',\n",
    "    'danceability',\n",
    "    'energy', \n",
    "    'instrumentalness',\n",
    "    'key',\n",
    "    'liveness',\n",
    "    'loudness',\n",
    "    'mode',\n",
    "    'speechiness',\n",
    "    'tempo',\n",
    "    'time_signature',\n",
    "    'valence',\n",
    "    'Year',\n",
    "]\n",
    "\n",
    "target = 'Success'\n",
    "\n",
    "ranges = [\n",
    "    (0,10),\n",
    "    (10,30),\n",
    "    (30,50),\n",
    "    (50,100)\n",
    "]\n",
    "\n",
    "big_frame = enumerate_popularity(ranges, big_frame)\n",
    "print(big_frame['Success'].value_counts())\n",
    "\n",
    "get_less = split_train_and_test(big_frame, 0.3)\n",
    "subset = get_less['training_set']\n",
    "\n",
    "data_sets = split_train_and_test(subset, 0.7)\n",
    "training_set = data_sets['training_set']\n",
    "test_set = data_sets['test_set']\n",
    "\n",
    "X = training_set[features]\n",
    "X = scale_data(X)\n",
    "Y = training_set[target]\n",
    "\n",
    "X_test = test_set[features]\n",
    "X_test = scale_data(X_test)\n",
    "Y_test = test_set[target]\n",
    "\n",
    "print_set_info(big_frame, Y, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MLPRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ab25a2a5b644>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m trained_ANN = MLPRegressor(\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mhidden_layer_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'logistic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MLPRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "trained_ANN = MLPRegressor(\n",
    "        hidden_layer_sizes = (10,),\n",
    "        solver='adam',\n",
    "        activation='logistic',\n",
    "        batch_size = int(0.01*X.shape[0]),\n",
    "        learning_rate='adaptive',\n",
    "        learning_rate_init=1,\n",
    "        verbose=False,\n",
    "        momentum=0.5,\n",
    "        alpha = 0.001,\n",
    "        max_iter = 10000,\n",
    "        random_state=1\n",
    "    )\n",
    "\n",
    "trained_ANN.fit(X,Y)\n",
    "show_results(trained_ANN, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
